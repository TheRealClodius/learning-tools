# MemoryOS MCP Server Environment Variables Sample
# Copy this to your .env.local file and fill in your actual API keys

# Existing API Keys (already configured)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
PERPLEXITY_API_KEY=your_perplexity_api_key_here  
OPENWEATHER_API_KEY=your_openweather_api_key_here

# NEW: Required for Run Summary Generation
GEMINI_API_KEY=your_gemini_api_key_here

# MemoryOS MCP Server Configuration
MEMORYOS_SERVER_URL=http://localhost:5000
MEMORYOS_API_KEY=your_memoryos_server_api_key_here
MEMORYOS_TIMEOUT=30

# MemoryOS User Configuration
MEMORY_USER_ID=default_user

# Notes:
# - MEMORYOS_SERVER_URL: URL of your MemoryOS MCP server (from your repo)
# - MEMORYOS_API_KEY: API key for authentication with your MemoryOS server
# - MEMORYOS_TIMEOUT: Request timeout in seconds (default: 30)
# - MEMORY_USER_ID: Unique identifier for your user in the memory system
# - GEMINI_API_KEY: Required for intelligent run summaries (tool usage, reasoning)
#
# To deploy your MemoryOS server:
# 1. Clone: https://github.com/TheRealClodius/MemoryOS-Private-Server-AP-Expert
# 2. Set up the server configuration and API keys
# 3. Run: python deploy_server.py
# 4. Update MEMORYOS_SERVER_URL and MEMORYOS_API_KEY above
# 5. Get Gemini API key from: https://aistudio.google.com/app/apikey
#
# Enhanced Memory Features:
# - Agent-driven Q&A storage using memory_conversation_add function
# - Agent-driven execution storage using memory_execution_add function  
# - Execution summaries include: reasoning approach, tools used, what worked/failed
# - Agent generates summaries and observations as needed
# - Memory functions available to AI agent for strategic storage
#
# Performance benefits:
# - ~50ms response time vs 15+ seconds with direct integration
# - GPU acceleration support for embeddings
# - Persistent embedding cache (no model reloading)
# - Multi-user isolation and scalability 